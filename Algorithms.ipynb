{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code has all algorithm which we proposed and we check it using two types of laplacian that is symmetic and unnormalized laplacian. \n",
    "And we have set the precision for the edge weigths here so we get desired results for the Petersen graph.\n",
    "Here we have used edge weigths as (f_i - f_j)^2. \n",
    "\n",
    "And we are doing it for just for graphs with edge weigth 1 or 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c2f9f61236b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;31m# GH 27101\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# TODO: remove Panel compat in 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY37\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'compat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import linalg as LA\n",
    "import networkx.linalg.algebraicconnectivity as alg\n",
    "import collections \n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "Results_ncut = pd.DataFrame(index = ['NUP','NP', 'NS', 'UnUP','UnP', 'UnS'])\n",
    "Results_conductance = pd.DataFrame(index = ['NUP','NP', 'NS', 'UnUP','UnP', 'UnS'])\n",
    "Graphs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This wil get us the similarity matrix W given the graph and the number of vertices n.\n",
    "# the vertices are number form 0 to n - 1.\n",
    "def get_matrix2(graph, n):\n",
    "    \n",
    "    w = np.zeros((n, n))\n",
    "   \n",
    "    for x in graph.keys() :\n",
    "        for y in graph[x]:\n",
    "            w[x][y] = 1\n",
    "            w[y][x] = 1\n",
    "\n",
    "    return w\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unnormalized_laplacian(w):\n",
    "    \n",
    "    D = w.sum(axis = 1)\n",
    "    \n",
    "    D = np.diag(D)  # The degree matrix D\n",
    "    \n",
    "    L = D - w\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_laplacian(w):\n",
    "    \n",
    "    D = w.sum(axis = 1)\n",
    "    D_sqrt = np.sqrt(D)\n",
    "    \n",
    "    D_1 = np.reciprocal(D_sqrt)\n",
    "    D_1 = np.diag(D_1)  \n",
    "    D = np.diag(D)\n",
    "    L = np.dot(D_1, np.dot(D - w, D_1))\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the fielder eigen vector given the similartiy matrix W.\n",
    "\n",
    "def get_fielder(l, n):  #Similairty matix W\n",
    "\n",
    "    eigvals, eigvecs = sp.linalg.eigh(l)# eigen values and eigen vectors of the unnormalized laplacian D - W \n",
    "    #print(\"Eigenvalues: \",eigvals, \"\\n\")\n",
    "    eigvecs = np.round( eigvecs, 5)\n",
    "    eigvals = np.round(eigvals, 4)\n",
    "    cardinality = 1\n",
    "    \n",
    "    fielder_eigval = eigvals[1]\n",
    "    \n",
    "    #print(fielder_eigval)\n",
    "    while(cardinality < n and abs(eigvals[cardinality] - fielder_eigval)<0.000001):\n",
    "        cardinality = cardinality + 1\n",
    "        \n",
    "    fielder = eigvecs.T[1:cardinality, :] #The 2nd smallest eigen vector of the laplacian L = D - W\n",
    "    \n",
    "    return fielder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks weather the graph has to connected components or not i.e is the garph paritioned into two clusters \n",
    "\n",
    "def check_partion(w, n): # Similarity matrix W and the number of vetrices n\n",
    "    \n",
    "    # We will do bfs and check if the graph is partitioned into two parts or not \n",
    "    explored = [0]*n \n",
    "    \n",
    "    queue = collections.deque([0])\n",
    "    \n",
    "    queue_size = 1\n",
    "    \n",
    "    while(queue_size != 0):\n",
    "        \n",
    "        node = queue.popleft()\n",
    "        queue_size -= 1\n",
    "        \n",
    "        if explored[node] == 0:\n",
    "            \n",
    "            explored[node] = 1\n",
    " \n",
    "            for i in range(0, n):\n",
    "                if(w[node][i] != 0):\n",
    "                    neighbour = i\n",
    "                    \n",
    "                    if(explored[neighbour] == 0):\n",
    "                        queue.append(neighbour)\n",
    "                        queue_size += 1\n",
    "    \n",
    "    # Just need to check if this graph has been partitioned into two parts or not \n",
    "    is_partitioned = False\n",
    "    \n",
    "    for node in explored:\n",
    "        if node == 0:\n",
    "            is_partitioned = True\n",
    "    \n",
    "    return is_partitioned  \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the graph has been paritioned into two parts we need to know what these partitions are this function gives us that\n",
    "# not only does it outputs the clusters but also a vector whose ith index is 1 if its in the first cluster otherwise 0.\n",
    "\n",
    "def get_partition(w, n): # the similrity matrix W and the number of vertices n\n",
    "    \n",
    "    # We will do bfs from a vertex and find out its conected component the other vertices which are not in the\n",
    "    # connected component are in the other cluster \n",
    "    clusters = [[], []]\n",
    "    explored = [0]*n\n",
    "    \n",
    "    \n",
    "    queue = collections.deque([0])\n",
    "    \n",
    "    queue_size = 1\n",
    "    \n",
    "    \n",
    "    while(queue_size != 0):\n",
    "        \n",
    "        node = queue.popleft()\n",
    "        queue_size -= 1\n",
    "        \n",
    "        if explored[node] == 0:\n",
    "            \n",
    "            explored[node] = 1\n",
    " \n",
    "            for i in range(0, n):\n",
    "                if(w[node][i] != 0):\n",
    "                    neighbour = i\n",
    "                    \n",
    "                    if(explored[neighbour] == 0):\n",
    "                        queue.append(neighbour)\n",
    "                        queue_size += 1\n",
    "    \n",
    "    \n",
    "    #If it a node is connected to vertex zero then its in cluster 0 otherwise its in cluster 1. \n",
    "    for node in range(0, n):\n",
    "        if explored[node] == 1:\n",
    "            clusters[0].append(node)\n",
    "        else:\n",
    "            clusters[1].append(node)\n",
    "    \n",
    "    return clusters, explored\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_weights(f, w, n):\n",
    "    \n",
    "    new_weight = []\n",
    "    D = w.sum(axis = 1)\n",
    "    D_sqrt = np.sqrt(D)\n",
    "    \n",
    "    for i in range(0, n):\n",
    "        for j in range(0, n):\n",
    "            if(w[i][j] != 0):\n",
    "                new_weight.append([np.dot((f[:,i] - f[:,j]).T,f[:,i] - f[:,j]), i, j])\n",
    "    \n",
    "    new_weight = [ [round(i, 3) for i in elem] for elem in new_weight]\n",
    "    new_weight = sorted(new_weight, reverse= True)\n",
    "    \n",
    "\n",
    "    return new_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use our current algorithm to partition the graph\n",
    "# This returns the clusters, the cluster_name vector and the edeges cut\n",
    "def get_clusters(f, w, n): # the similarity matrix and the number of vertices\n",
    "    \n",
    "    new_weight = get_edge_weights(f, w, n)\n",
    "    \n",
    "    new_weight.sort(reverse= True)\n",
    "\n",
    "    new_weight = collections.deque(new_weight)\n",
    "\n",
    "    new_w = w.copy() # Here we copy the similarity matrix so that when we make changes to new_w nothing happens to the origianl similarty matrix\n",
    "\n",
    "    edges_cut = []\n",
    "    while(check_partion(new_w, n) == False):  # keep on removing edges until we have a parition\n",
    "        edge_remove = new_weight.popleft()\n",
    "\n",
    "        u = edge_remove[1]\n",
    "        v = edge_remove[2]\n",
    "\n",
    "        if(new_w[u][v] != 0):\n",
    "            edges_cut.append([u,v])\n",
    "\n",
    "        new_w[u][v] = 0\n",
    "        new_w[v][u] = 0\n",
    "        \n",
    "    \n",
    "    clusters, cluster_name = get_partition(new_w, n) \n",
    "    \n",
    "    # this part changes the cluster_name from a list to numpy array (This step helps to write easy codes)\n",
    "    cluster_name = np.asarray(cluster_name)\n",
    "    cluster_name = np.reshape(cluster_name, (1,n))\n",
    "    \n",
    "    \n",
    "    return clusters, cluster_name, edges_cut \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncut(cluster_name, w, n):\n",
    "    \n",
    "    cluster_name = np.asarray(cluster_name)\n",
    "    cluster_name = np.reshape(cluster_name, (1,n))\n",
    "    \n",
    "    mull_1 = cluster_name\n",
    "    mull_2 = np.ones((1,n)) - mull_1\n",
    "    \n",
    "    w_1 = np.dot(mull_1, np.dot(w, np.ones((n,1))))\n",
    "    w_2 = np.dot(mull_2, np.dot(w, np.ones((n,1))))\n",
    "    \n",
    "    \n",
    "    cut = np.dot(mull_1, np.dot(w,mull_2.T))\n",
    "    #print(cut, w_1,w_2)\n",
    "    \n",
    "    ans = cut*(1/w_1 + 1/w_2)\n",
    "    ans_1 = cut/min(w_1, w_2)\n",
    "    \n",
    "    return ans[0][0], ans_1[0][0] \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cut(clusters, w, n):\n",
    "    cut = []\n",
    "    for x in clusters[0]:\n",
    "        for y in clusters[1]:\n",
    "            if(w[x][y] != 0):\n",
    "                cut.append([x,y])\n",
    "    return cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(l, n, w):\n",
    "    \n",
    "    \n",
    "    fielder = get_fielder(l, n)\n",
    "    add_col_ncut = []\n",
    "    add_col_con = []\n",
    "    \n",
    "    print(\"Fielder Eigenvectors:\", fielder)\n",
    "    print(\"Edge weights:\", get_edge_weights(fielder, w, n))\n",
    "    \n",
    "    \n",
    "    clusters, cluster_predict , edges_cut = get_clusters(fielder, w, n) \n",
    "    nc, c = ncut(cluster_predict, w, n)\n",
    "    print(\"\\nFielder Cardinality:\", fielder.shape[0])\n",
    "    print(\"\\nCurrent Updated Algorithm\\n\")\n",
    "    print(\"Ncut value:\", nc)\n",
    "    print(\"Conductance:\", c)\n",
    "    print(\"Clusters:\", clusters)\n",
    "    print(\"Clusters we get using our current algorithm: \", cluster_predict)\n",
    "    print(\"The edges removed by the algorithm:\",edges_cut)\n",
    "    print(\"The edge cut of the clusters:\", get_cut(clusters, w, n))\n",
    "    \n",
    "    add_col_ncut.append(nc)\n",
    "    add_col_con.append(c)\n",
    "    \n",
    "    clusters, cluster_predict , edges_cut = get_clusters(np.reshape(fielder[0,:],(1,n)), w, n) \n",
    "    nc, c = ncut(cluster_predict, w, n)\n",
    "    print(\"\\nCurrent Algorithm\\n\")\n",
    "    print(\"Ncut value:\", nc)\n",
    "    print(\"Conductance:\", c)\n",
    "    print(\"Clusters:\", clusters)\n",
    "    print(\"Clusters we get using our current algorithm: \", cluster_predict)\n",
    "    print(\"The edges removed by the algorithm:\",edges_cut)\n",
    "    print(\"The edge-cut of the clusters:\", get_cut(clusters, w, n))\n",
    "    \n",
    "    add_col_ncut.append(nc)\n",
    "    add_col_con.append(c)\n",
    "    \n",
    "    cluster_predict = [0]*n\n",
    "    \n",
    "    clusters = [[], []]\n",
    "    for i in range(0, n):\n",
    "        if(fielder[0][i] <= 0):\n",
    "            cluster_predict[i] = 0\n",
    "            clusters[0].append(i)\n",
    "        else:\n",
    "            cluster_predict[i] = 1\n",
    "            clusters[1].append(i)\n",
    "    \n",
    "    nc, c = ncut(cluster_predict, w, n)\n",
    "    print(\"\\nSpectral clustering Algorithm\\n\")\n",
    "    print(\"Ncut value:\", nc)\n",
    "    print(\"Conductance:\", c)\n",
    "    print(\"Clusters:\", clusters)\n",
    "    print(\"Clusters we get using our current algorithm: \", cluster_predict)\n",
    "    print(\"The edge-cut of the clusters:\", get_cut(clusters, w, n))\n",
    "    add_col_ncut.append(nc)\n",
    "    add_col_con.append(c)\n",
    "    \n",
    "    \n",
    "    return add_col_ncut, add_col_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_1(l, n, w):\n",
    "    \n",
    "    \n",
    "    fielder = get_fielder(l, n)\n",
    "    add_col_ncut = []\n",
    "    add_col_con = []\n",
    "    \n",
    "    \n",
    "    clusters, cluster_predict , edges_cut = get_clusters(fielder, w, n) \n",
    "    nc, c = ncut(cluster_predict, w, n)\n",
    "    \n",
    "    add_col_ncut.append(nc)\n",
    "    add_col_con.append(c)\n",
    "    \n",
    "    clusters, cluster_predict , edges_cut = get_clusters(np.reshape(fielder[0,:],(1,n)), w, n) \n",
    "    nc, c = ncut(cluster_predict, w, n)\n",
    "    \n",
    "    add_col_ncut.append(nc)\n",
    "    add_col_con.append(c)\n",
    "    \n",
    "    cluster_predict = [0]*n\n",
    "    \n",
    "    clusters = [[], []]\n",
    "    for i in range(0, n):\n",
    "        if(fielder[0][i] <= 0):\n",
    "            cluster_predict[i] = 0\n",
    "            clusters[0].append(i)\n",
    "        else:\n",
    "            cluster_predict[i] = 1\n",
    "            clusters[1].append(i)\n",
    "    \n",
    "    nc, c = ncut(cluster_predict, w, n)\n",
    "    add_col_ncut.append(nc)\n",
    "    add_col_con.append(c)\n",
    "    \n",
    "    \n",
    "    return add_col_ncut, add_col_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalized_results(graph, print_results):\n",
    "\n",
    "    n = graph[1][0]\n",
    "    graph = graph[0][0]\n",
    "    w = get_matrix2(graph, n)\n",
    "\n",
    "    l = get_unnormalized_laplacian(w)\n",
    "    \n",
    "    if(print_results == True):\n",
    "        print(\"\\nUnnormalized results\\n\")\n",
    "        return get_results(l, n, w)\n",
    "    else:\n",
    "        return get_results_1(l, n, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_results(graph, print_results):\n",
    "\n",
    "    n = graph[1][0]\n",
    "    graph = graph[0][0]\n",
    "    w = get_matrix2(graph, n)\n",
    "\n",
    "    l = get_normalized_laplacian(w)\n",
    "    \n",
    "    if(print_results == True):\n",
    "        print(\"\\nNormalized results\\n\")\n",
    "        return get_results(l, n, w)\n",
    "    else:\n",
    "        return get_results_1(l, n, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(graph, print_results):\n",
    "    \n",
    "    add_col_ncut, add_col_con  = [], []\n",
    "    \n",
    "    add_col_ncut, add_col_con = normalized_results(graph[1], print_results)\n",
    "    un, uc = unnormalized_results(graph[1], print_results)\n",
    "    add_col_ncut += un\n",
    "    add_col_con += uc\n",
    "    \n",
    "    Results_ncut[graph[0]], Results_conductance[graph[0]] = add_col_ncut, add_col_con\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Petersen = ['Petersen', [[{0 : [2, 3],\n",
    "         1 : [4, 3],\n",
    "         2 : [0, 4],\n",
    "         3 : [0, 1],\n",
    "         4 : [1, 2],\n",
    "         5 : [6, 0],\n",
    "         6 : [7, 1],\n",
    "         7 : [8, 2],\n",
    "         8 : [9, 3],\n",
    "         9 : [5, 4]\n",
    "             }],\n",
    "        [10]]]\n",
    "\n",
    "Graphs.append(Petersen)\n",
    "show_results(Petersen, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Enneahedron = ['Enneahedron', [[{0 : [1, 3, 4],\n",
    "         1 : [0, 2, 4, 5],\n",
    "         2 : [1, 3, 6],\n",
    "         3 : [0, 7, 6, 2],\n",
    "         4 : [0, 1, 5, 6, 7],\n",
    "         5 : [1, 4, 6],\n",
    "         6 : [2, 3, 4, 5, 7],\n",
    "         7 : [4, 3, 6],\n",
    "             }],\n",
    "        [8]]]\n",
    "Graphs.append(Enneahedron)\n",
    "show_results(Enneahedron, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Enneahedron_1 = ['Enneahedron_1',[[{0 : [1, 3, 4],\n",
    "         1 : [0, 2, 4, 6, 5],\n",
    "         2 : [1, 3, 5],\n",
    "         3 : [0, 4, 7, 5, 2],\n",
    "         4 : [0, 1, 3, 6],\n",
    "         5 : [1, 7, 3, 2],\n",
    "         6 : [1, 3, 4, 7],\n",
    "         7 : [6, 5],\n",
    "             }],\n",
    "        [8]]]\n",
    "Graphs.append(Enneahedron_1)\n",
    "show_results(Enneahedron_1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Cockroach = ['Cockroach',[[{0 : [1],\n",
    "         1 : [0, 2],\n",
    "         2 : [1, 3],\n",
    "         3 : [2, 4, 8],\n",
    "         4 : [3, 5, 7],\n",
    "         5 : [4, 6],\n",
    "         6 : [5, 7],\n",
    "         7 : [6, 8, 4],\n",
    "         8 : [7, 9, 3],\n",
    "         9 : [8, 10],\n",
    "         10 : [11]\n",
    "             }],\n",
    "        [12]]]\n",
    "Graphs.append(Cockroach)\n",
    "show_results(Cockroach, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Cockroach_1 = ['Cockroach_1', [[{0 : [1, 11],\n",
    "         1 : [0, 2],\n",
    "         2 : [1, 3],\n",
    "         3 : [2, 4, 8],\n",
    "         4 : [3, 5, 7],\n",
    "         5 : [4, 6],\n",
    "         6 : [5, 7],\n",
    "         7 : [6, 8, 4],\n",
    "         8 : [7, 9, 3],\n",
    "         9 : [8, 10],\n",
    "         10 : [11],\n",
    "         11 : [0]    }],\n",
    "        [12]]]\n",
    "\n",
    "Graphs.append(Cockroach_1)\n",
    "show_results(Cockroach_1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Path_point  = ['Path_point',[[{0 : [1],\n",
    "         1 : [0, 2],\n",
    "         2 : [1, 3],\n",
    "         3 : [2, 4],\n",
    "         4 : [3, 5],\n",
    "         5 : [4, 6],\n",
    "         6 : [5, 7],\n",
    "         7 : [6, 8],\n",
    "         8: [7, 9],\n",
    "         9: [8, 10],\n",
    "         10:[9, 11],\n",
    "         11 :[0,1,2,3,4,5,6,7,8,9,10]\n",
    "                }],\n",
    "        [12]]]\n",
    "\n",
    "Graphs.append(Path_point)\n",
    "show_results(Path_point, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Two_clusters = ['Two_clusters', [[{0 : [1, 2, 3],\n",
    "         1 : [0, 2, 3, 4],\n",
    "         2 : [0, 1, 3],\n",
    "         3 : [0, 1, 2],\n",
    "         4 : [5, 6, 7],\n",
    "         5 : [4, 6, 7],\n",
    "         6 : [4, 5, 7],\n",
    "         7 : [4, 5, 6]\n",
    "        }],\n",
    "        [8]]]\n",
    "\n",
    "Graphs.append(Two_clusters)\n",
    "show_results(Two_clusters, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Discrete_moons = {}\n",
    "\n",
    "for i in range(0, 19):\n",
    "    Discrete_moons[i] = [i + 1]\n",
    "    Discrete_moons[i + 20] = [i + 21]\n",
    "\n",
    "print(Discrete_moons)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    Discrete_moons[i].append(19 - i)\n",
    "    Discrete_moons[i + 20].append(39 - i)\n",
    "\n",
    "for i in range(0, 5):\n",
    "    Discrete_moons[i + 10].append(24 - i)\n",
    "#print(Discrete_moons)\n",
    "\n",
    "D_M = ['Discrete_moons',[[Discrete_moons], [40]]]\n",
    "\n",
    "Graphs.append(D_M)\n",
    "show_results(D_M, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Double_Tree = {}\n",
    "\n",
    "for i in range(1,10):\n",
    "    Double_Tree[i] = [math.floor((i - 1)/2)]\n",
    "    Double_Tree[i + 10] = [10 + math.floor((i - 1)/2)]\n",
    "\n",
    "Double_Tree[0] = [10]\n",
    "\n",
    "D_T = ['Double_Tree',[[Double_Tree], [20]]]\n",
    "\n",
    "Graphs.append(D_T)\n",
    "show_results(D_T, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Double_Tree1 = {}\n",
    "\n",
    "for i in range(1,10):\n",
    "    Double_Tree1[i] = [math.floor((i - 1)/2)]\n",
    "    Double_Tree1[i + 10] = [10 + math.floor((i - 1)/2)]\n",
    "\n",
    "Double_Tree1[0] = [10]\n",
    "\n",
    "for i in range(5,9):\n",
    "     Double_Tree1[i].append(10+i)\n",
    "for i in range(0,9):\n",
    "    Double_Tree1[i].append((i+1)%10)\n",
    "D_T1 = ['Double_Tree1',[[Double_Tree1], [20]]]\n",
    "\n",
    "Graphs.append(D_T1)\n",
    "print(D_T1)\n",
    "show_results(D_T1, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for graph in Graphs:\n",
    "    show_results(graph, False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Results_conductance.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Results_ncut.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Results_conductance.loc['UnP', :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_cuts = []\n",
    "\n",
    "for i in range(1, 2**10 - 1):\n",
    "    cluster_predict = [1]*10\n",
    "    \n",
    "    for j in range(0,10):\n",
    "        if(2**j & i != 0):\n",
    "            cluster_predict[j] = 0\n",
    "    \n",
    "    #print(cluster_predict)\n",
    "    graph = Petersen[1][0]\n",
    "    graph = graph[0]\n",
    "    n = Petersen[1][1]\n",
    "    n  = n[0]\n",
    "    #print(ncut(cluster_predict, get_matrix2(graph, n), n))\n",
    "    if(ncut(cluster_predict, get_matrix2(graph, n), n) == ncut([1,1,1,1,1,0,0,0,0,0], get_matrix2(graph, n), n)):\n",
    "        \n",
    "        clusters = [[], []]\n",
    "        for i in range(0, 10):\n",
    "            clusters[cluster_predict[i]].append(i)\n",
    "            \n",
    "        optimal_cuts.append(clusters)\n",
    "\n",
    "for x in optimal_cuts:\n",
    "    print(x)\n",
    "print(len(optimal_cuts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Enneahedron_1[1][0][0]\n",
    "for i in d.keys():\n",
    "    for j in d[i]:\n",
    "        if(i < j):\n",
    "            print(str(i) + ' ' + str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [0.46236,  0.16479, -0.33309, -0.08359,  0.50135, -0.49733,  0.1138,  -0.35984]\n",
    "\n",
    "for i in range(0,8):\n",
    "    print(str(i) + \", \" + str(v[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RL_Ncut = Results_ncut.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_SLP = RL_Ncut['SLP'].values\n",
    "y_UnP = RL_Ncut['UnP'].values\n",
    "y_RwP = RL_Ncut['RwP'].values\n",
    "y_SLS = RL_Ncut['SLS'].values\n",
    "y_UnS = RL_Ncut['UnS'].values\n",
    "y_RwS = RL_Ncut['RwS'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
